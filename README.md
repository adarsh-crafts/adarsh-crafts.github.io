My long-term research goal is to advance **trustworthy machine learning methods for healthcare**. I am particularly interested in computer vision, natural language processing, and generative models, with applications to **medical imaging and clinical decision support**.

[Email](mailto:nadarsh337@gmail.com) / [Medium](https://medium.com/@adarsh-ai) / [LinkedIn](https://www.linkedin.com/in/adarshn-256455279/) / [GitHub](https://github.com/adarsh-crafts)  / [Google Scholar](https://scholar.google.com/citations?user=Sm8_hWgAAAAJ&hl=en)


## Research experience

**Machine Learning Research Intern** @ [ I2CS Research Group, IIITK](https://i2cs.iiitkottayam.ac.in/) _(May 2025 - Present)_    
Carried out supervised research in the field of **Vision-Language Models**, focusing on enhancing multimodal alignment.

- **Engineered** and trained a custom **Vision-Language Model (VLM)** by integrating a fine-tuned CLIP vision encoder with a 7B-parameter LLM.  

- **Implemented** a novel architecture from recent literature to enhance the vision-language bridge, **improving model performance**.  

- **Benchmarked** the custom VLM's performance against established vision-language baselines on key metrics. 

- **Authored** key sections of the research manuscript for a publication, including the literature review, architectural description of the models, and comparative performance analysis.

**A Comparative Analysis of Generative Models for Medical Image Augmentation** _(Ongoing)_

- **Leading** an independent research project to investigate the performance of modern generative models and the impact of pre-processing for augmenting dermatological datasets and improving diagnostic classifier performance.

- **Implementing** and **benchmarking** state-of-the-art generative architectures, including StyleGAN-based models and Denoising Diffusion Probabilistic Models (DDPMs), to synthesize high-fidelity 256x256 medical images.

- **Evaluating** the quality and clinical utility of synthetic images through both quantitative metrics (e.g., FID) and the performance improvement of a downstream ResNet-based classifier.


## Publications

**An End-to-End Sign Language Translation Pipeline from Static Gestures to English Using T5**  
_N A Adarsh Pritam, Asha Kurian. Proceedings of the International Conference on Emerging Technologies in Computing and Communication (ETCC 2025)_ [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11108641) [Publication](https://ieeexplore.ieee.org/document/11108641)

- Proposed an **end-to-end ASL-to-English translation system** that integrates vision-based gesture recognition (MediaPipe, Teachable Machine) with a fine-tuned FLAN-T5 model for natural language generation.

- Achieved **substantial improvements in translation quality** (BLEU: 0.74, ROUGE-L: 0.89), producing fluent and contextually coherent English sentences.

- Delivered a **lightweight**, **modular prototype** suitable for deployment on consumer hardware, highlighting its potential as an **assistive communication** tool in education and healthcare settings. 


## Projects

**Built-from-Scratch Personalized Conversational-AI to Mimic Communication Style via Personal Chat Logs** _[GitHub](https://github.com/adarsh-crafts/personalized-conversational-ai)_  
_(Ongoing)_

- Designed an end-to-end custom language model to **emulate individual communication styles** using personal chat logs.

- Implemented data extraction, cleaning, and a custom **BPE tokenizer**, followed by training a **decoder-only transformer** from scratch.

- Applied **QLoRA**-based fine-tuning for **parameter-efficient adaptation**, demonstrating potential for personalized dialogue systems and low-resource model customization.  

**Reimplemented a LLaMA-style Transformer from Scratch in PyTorch** 
_[GitHub](https://github.com/adarsh-crafts/llama-llm-from-scratch)_

- Developed an **educational reimplementation of a modern LLaMA-inspired large language model**, constructed entirely from first principles in PyTorch.

- **Implemented** and analyzed key components of transformer architecture, including **multi-head attention**, **grouped-query attention (GQA)**, and **rotary positional embeddings (RoPE)**.

_[See more projects on GitHub](https://github.com/adarsh-crafts)_


## My Blogs

**A Beginner's Guide to Multi-Head Self-Attention in LLMs**  _[read here](https://medium.com/@adarsh-ai/a-beginners-guide-to-multi-head-self-attention-in-llms-1a4ea8be6fb2)_

How do models like Llama and GPT understand context so effectively? The answer lies in multi-head self-attention. In this post, I provide a step-by-step breakdown of this foundational technology, translating complex theory into intuitive concepts.  

**Build a Byte-Pair Encoding (BPE) Tokenizer from Scratch in Python** _[read here](https://medium.com/@adarsh-ai/build-a-byte-pair-encoding-bpe-tokenizer-from-scratch-in-python-0dc32c6410f7)_

This is part of my journey to understand large language models from first principles. I’m building a LLaMA-like model from scratch, documenting each component in this blog series.

_[See more blogs on Medium](https://medium.com/@adarsh-ai)_


<div style="display: flex; align-items: center;">

  <div style="flex: 1;">
    <img src="images\BPE.jpg" width="256">
  </div>

  <div style="flex: 2; padding-left: 15px;">
    <b>Build a Byte-Pair Encoding (BPE) Tokenizer from Scratch in Python</b><br>
    This is part of my journey to understand large language models from first principles. I’m building a LLaMA-like model from scratch, documenting each component in this blog series. <br>
    <i>July 2025</i>, <a href="https://medium.com/@adarsh-ai/build-a-byte-pair-encoding-bpe-tokenizer-from-scratch-in-python-0dc32c6410f7">read here</a>
  </div>

</div>



## Open Source contributions

For a complete overview of my open source contributions, check [this GitHub search query](https://github.com/search?q=is%3Apr+author%3Aadarsh-crafts+is%3Apublic&type=pullrequests). Below is the same information organized by year.

### 2025

- Improved the model's positional embedding layer by refactoring duplicated logic to enhance code clarity and robustness _**(OpenAI)**_ <span style="color:gold">[approved]</span> 
- Improved code documentation by adding comprehensive docstrings to utility and helper functions _**(OpenAI)**_ <span style="color:#90EE90">[merged]</span>
- Improved an example script by removing dead code to enhance long-term code health and maintainability _**(OpenAI)**_ <span style="color:#90EE90">[merged]</span>
- Refactored a utility function for clarity, improving code readability and long-term maintainability _**(OpenAI)**_ <span style="color:#90EE90">[merged]</span>
- Resolved UnicodeDecodeError in a txt file-reader by specifying encoding for cross-platform compatibility _**(FreeCodeCamp)**_ <span style="color:#90EE90">[merged]</span>
- Fixed typo in function docstring to improve clarity _**(FreeCodeCamp)**_ <span style="color:#90EE90">[merged]</span>


## Certifications

- **AWS Certified AI Practitioner** - _Amazon Web Services (AWS)_

- **AWS Certified AI Practitioner Early Adopter** - _Amazon Web Services (AWS)_

- **Mathematics for Machine Learning and Data Science Specialization** - _DeepLearning.AI_

- **Google Business Intelligence Specialization** - _Google_

- **Google Data Analytics Specialization** - _Google_